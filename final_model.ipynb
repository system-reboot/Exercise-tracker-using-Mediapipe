{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to calculate the angle between hip, knee and ankle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angles(a,b,c):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "\n",
    "    radians = np.arctan2(c[1]-b[1],c[0]-b[0]) - np.arctan2(a[1]-b[1],a[0]-b[0])\n",
    "    angle = np.abs(radians*180.0/np.pi)\n",
    "\n",
    "    if angle > 180:\n",
    "        angle = 360 - angle\n",
    "    return angle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('Knee Exercise Video.mp4')\n",
    "\n",
    "# Rep counter variables\n",
    "rep = 0\n",
    "stage = None\n",
    "\n",
    "# variable to avoid multiple rep counts in a single up stage condition only\n",
    "flag = 0\n",
    "\n",
    "# defining timer variables\n",
    "start_time = 0\n",
    "end_time = 0\n",
    "timer = 8\n",
    "\n",
    "# variable to calculate angle between hip, knee and ankle\n",
    "angle = 0\n",
    "\n",
    "# width, height and frame of output window\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Define the codec and create VideoWriter object.The output is stored in 'output.mp4' file.\n",
    "out = cv2.VideoWriter('output.mp4', cv2.VideoWriter_fourcc('P','I','M','1'), fps, (width, height))\n",
    "\n",
    "# Define the Kalman filter\n",
    "kf = cv2.KalmanFilter(4, 2)\n",
    "kf.measurementMatrix = np.array([[1, 0, 0, 0], [0, 1, 0, 0]], np.float32)\n",
    "kf.transitionMatrix = np.array([[1, 0, 1, 0], [0, 1, 0, 1], [0, 0, 1, 0], [0, 0, 0, 1]], np.float32)\n",
    "kf.processNoiseCov = np.array([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]], np.float32) * 0.03\n",
    "\n",
    "# Initialize the Kalman filter with the initial position\n",
    "t = 0\n",
    "\n",
    "with mp_pose.Pose( min_detection_confidence=0.90,min_tracking_confidence=0.90) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Changing frame colors from BGR to RGB\n",
    "        image = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        # Extract Landmarks\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "            # Get coordinates of hip, knee and ankle \n",
    "            hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x,landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "            ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "\n",
    "            if (t==0):\n",
    "                kf.statePost = np.array([knee[0], knee[1], 0, 0], np.float32)\n",
    "                t = 1\n",
    "\n",
    "            # Use the Kalman filter to predict the next position of the knee\n",
    "            kf.predict()\n",
    "\n",
    "            # Use the current position of the knee as the measurement\n",
    "            kf.correct(np.array([knee[0], knee[1]], np.float32))\n",
    "\n",
    "            # Get the predicted position of the knee\n",
    "            knee = (kf.statePost[0]), (kf.statePost[1])\n",
    "\n",
    "            \n",
    "            # Calculate angle of each frame\n",
    "            angle = calculate_angles(hip,knee,ankle)\n",
    "\n",
    "            # Visualize angle\n",
    "            cv2.putText(image, str(\"{0:.3f}\".format(angle)), tuple(np.multiply(knee, [width, height]).astype(int)), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,100), 2, cv2.LINE_AA)\n",
    "\n",
    "            # rep counter condition\n",
    "            if angle>140:\n",
    "                stage = 'down'\n",
    "                timer = 8\n",
    "                if (end_time -start_time) < 8:\n",
    "                    cv2.putText(image, 'Keep your knee bent',(350,30), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,0,0), 2, cv2.LINE_AA)\n",
    "\n",
    "                flag = 0\n",
    "\n",
    "            if angle<140 and stage=='down':\n",
    "                stage = 'up'\n",
    "                start_time = end_time = time.time()\n",
    "\n",
    "            elif angle<140 and stage=='up':\n",
    "                end_time = time.time()\n",
    "\n",
    "                if (end_time -start_time) >= 8 and flag == 0:\n",
    "                    rep+=1\n",
    "                    flag = 1\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Render timer\n",
    "        count = int(timer - (end_time -start_time))\n",
    "        if (count<0):\n",
    "            count = 0\n",
    "        if (angle>140):\n",
    "            count = timer\n",
    "        cv2.circle(image,(780,40),42,(153,153,255),-1)\n",
    "        cv2.putText(image,'Timer', (750,30), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,0), 2, cv2.LINE_AA)\n",
    "        cv2.putText(image,str(count), (772,65), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Render rep counter\n",
    "        cv2.rectangle(image,(0,0),(200,90),(153,153,255),-1)\n",
    "        # Rep data\n",
    "        cv2.putText(image,'Reps', (30,30), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (32,32,32), 2, cv2.LINE_AA)\n",
    "        cv2.putText(image,str(rep), (45,60), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2, cv2.LINE_AA)\n",
    "        # Stage data\n",
    "        cv2.putText(image,'Stage', (120,30), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,0), 2, cv2.LINE_AA)\n",
    "        cv2.putText(image,stage, (125,60), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "\n",
    "        # Changing frame colors from RGB to BGR\n",
    "        image.flags.writeable = False\n",
    "        image = cv2.cvtColor(image,cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Render Detection\n",
    "        mp_drawing.draw_landmarks(image,results.pose_landmarks,mp_pose.POSE_CONNECTIONS,mp_drawing.DrawingSpec(color=(245,117,66),thickness=2,circle_radius=2),\n",
    "                                    mp_drawing.DrawingSpec(color=(245,66,230),thickness=2,circle_radius=2))\n",
    "\n",
    "        # Write the frame into the file 'output.mp4'\n",
    "        out.write(image)\n",
    "        \n",
    "        # Displaying the video\n",
    "        cv2.imshow('Mediapipe feed',image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    # Release video writer\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "80ba4016e8ec853d7b55d6915013d2adae47c4b5f908295f8089a04cc277b65d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
